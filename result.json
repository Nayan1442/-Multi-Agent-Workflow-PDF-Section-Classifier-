{
    "Technical": [
        "AI Internship Interview - Q&A (Nayan Agrawal)\nQ: Tell me more about your Intrusion Detection project.\nA: I worked on an Intrusion Detection System using the NSL-KDD dataset. I combined CNN and\nTransformer models to capture both local and long-range patterns. I also added attention\nmechanisms and SE blocks to improve accuracy, achieving over 99% accuracy.\nQ: What role did you personally play in the project?\nA: I handled the entire pipeline - from data preprocessing to model design, training, and evaluation\nusing TensorFlow. I focused on tuning the model and analyzing metrics like F1-score to improve\nminority class performance.\nQ: What was the biggest challenge you faced?\nA: Handling class imbalance was a challenge. Some attack types were rare, leading to biased\nresults. I solved this using class weights and sampling techniques.\nQ: What would you improve in your model?\nA: I'd explore ensemble models and deploy the system with APIs. I'd also integrate explainability\ntools like SHAP for transparency.\nQ: How did you evaluate your model's performance?\nA: Besides accuracy, I used F1-score, precision, recall, and confusion matrix, especially to check\nminority class performance.\nQ: How does a CNN work and why did you use it?\nA: CNNs use filters to extract spatial features. In my project, they helped detect local patterns in\nconnection features without manual feature engineering.\nQ: What is a Transformer?\nA: Transformers use self-attention to process all inputs in parallel and model long-range\ndependencies efficiently."
    ],
    "This section falls under the category of ['Technical'].": [
        "Q: What is attention vs cross-attention?\nA: Attention allows the model to focus on relevant parts of input. Cross-attention is used when one\nsequence attends to another - useful in dual-branch or multi-modal models.\nQ: What is gradient descent?\nA: It's an optimization technique that updates model parameters by minimizing the loss function\nusing calculated gradients.\nQ: What is Agentic AI?\nA: Agentic AI enables systems to act autonomously, perceive their environment, plan, and take\nactions to achieve goals.\nQ: How is Agentic AI different from traditional AI?\nA: Traditional AI is reactive and single-task; Agentic AI is proactive, goal-oriented, and can handle\nmulti-step tasks independently.\nQ: What frameworks support Agentic AI?\nA: CrewAI, AutoGPT, LangGraph, ReAct, and BabyAGI are popular frameworks for building\nagent-based systems.\nQ: Can you design a simple agent-based system?\nA: Yes. A research assistant agent could take a topic, search online, summarize sources, and export\na PDF using tools and planning logic.\nQ: How would you explain AI to a non-technical person?\nA: AI is like teaching a computer to learn from examples - just like we learn from experience.\nQ: What if your model fails in production?\nA: I'd check for data drift, model version mismatch, or unhandled edge cases. I'd retrain, test, and\nadd monitoring tools.\nQ: Why this internship?"
    ],
    "This section falls under ['Technical'].": [
        "A: It matches my passion for AI and gives me an opportunity to apply my skills to real-world\nchallenges while learning from experienced professionals.\nQ: Where do you see yourself in 5 years?\nA: Working as an AI Engineer or Researcher, contributing to intelligent and agent-based automation\nsystems.\nQ: Do you keep yourself updated with AI trends?\nA: Yes. I read arXiv papers, follow Towards Data Science, and explore projects like AutoGPT,\nLangChain, and CrewAI."
    ]
}